# -*- coding: utf-8 -*-
"""Soft_project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uRricdiJ6spOzCaqgXaoV9Huv70sc3aK
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
 # Importing dependencies
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, ConfusionMatrixDisplay
from scipy import stats
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import accuracy_score
SEED=30

# Load the dataset
data = pd.read_csv('/content/sample_data/dataset_phishing.csv')

# Define class labels
classes = {0: 'phishing', 1: 'legitimate'}

from sklearn.utils import resample

# Separate classes
phishing = data[data['status'] == 'phishing']
legitimate = data[data['status'] == 'legitimate']

# Downsample legitimate
legitimate_downsampled = resample(legitimate,
                                replace=False,    # without replacement
                                n_samples=len(phishing),  # match minority
                                random_state=SEED)

# Combine
data_balanced = pd.concat([phishing, legitimate_downsampled])

phishing_upsampled = resample(phishing,
                             replace=True,     # with replacement
                             n_samples=len(legitimate),  # match majority
                             random_state=SEED)

data_balanced = pd.concat([phishing_upsampled, legitimate])

data.isnull().sum()[data.isnull().sum() > 0]

# Separate features and target variable
X = data.drop('status', axis=1)
y = data['status']

# Separate features and target variable
X = data.drop('status', axis=1)
y = data['status']

# Remove rows with NaN values in the target variable
X = X[~y.isnull()]  # Keep rows in X where y is not null
y = y[~y.isnull()]  # Keep rows in y where y is not null

# Convert the target variable 'y' to a numerical type (0 for 'phishing', 1 for 'legitimate')
# This is required for calculating point-biserial correlation which expects numerical inputs.
y_numeric = y.map({'phishing': 0, 'legitimate': 1})

# --- Check and handle non-numeric columns in X ---
print("Data types of X columns before conversion:")
print(X.dtypes)

# Identify non-numeric columns (excluding 'object' which might hold numbers as strings, handle carefully)
# Let's focus on converting columns that *should* be numeric but might be 'object'
# A common cause is mixed types or string representations of numbers
for col in X.columns:
    # Attempt to convert to numeric, forcing errors to NaN
    X[col] = pd.to_numeric(X[col], errors='coerce')

# After conversion, check for any columns that are still non-numeric (like object or category if not handled)
# Or check for columns that are now all NaN if conversion failed
non_numeric_cols_after = X.select_dtypes(exclude=np.number).columns
if len(non_numeric_cols_after) > 0:
    print("\nNon-numeric columns remaining after attempted conversion:")
    print(non_numeric_cols_after)
    # You might need to drop these columns if they cannot be converted
    # X = X.drop(columns=non_numeric_cols_after)
    # Or handle NaNs introduced by 'coerce' depending on your strategy
    # X = X.fillna(X.mean()) # Example: fill NaNs with mean

# For point-biserial correlation, ensure no infinite values either
X = X.replace([np.inf, -np.inf], np.nan)
# Handle any remaining NaNs, e.g., by dropping rows or filling
# Dropping rows might remove data points where y is also non-numeric, which is already handled above.
# Let's fill with 0 or mean, assuming NaNs should not exist after cleaning
X = X.fillna(0) # Or use X.mean()

print("\nData types of X columns after handling:")
print(X.dtypes)
# --- End of handling non-numeric columns ---


# Calculate feature importance using Mutual Information and Point-Biserial correlation
point_biserial_coefs = []
# Iterate through columns of X, ensuring they are numeric
for i in range(X.shape[1]):
    col_data = X.iloc[:, i]

    # Ensure the column data is numerical and does not contain only identical values
    # pointbiserialr requires variation in the numeric variable
    if pd.api.types.is_numeric_dtype(col_data) and col_data.nunique() > 1:
        try:
            # Use the numerical version of y for point-biserial correlation
            coef = stats.pointbiserialr(col_data, y_numeric)[0]
            point_biserial_coefs.append(coef)
        except ValueError as e:
            print(f"Could not calculate point-biserial correlation for column {X.columns[i]} due to error: {e}")
            point_biserial_coefs.append(np.nan) # Append NaN or 0 if calculation fails
    else:
        print(f"Skipping column {X.columns[i]} for point-biserial correlation (not numeric or constant value).")
        point_biserial_coefs.append(np.nan) # Append NaN for non-applicable columns


# Mutual information can handle categorical target variables, so we use the original y
# Ensure X only contains numerical or suitable categorical data for mutual_info_classif
# mutual_info_classif works with numerical, boolean, or discrete (integer) data.
# Convert any remaining 'object' columns that represent categories to category dtype or one-hot encode if necessary for mutual_info_classif
# For this dataset, the initial check suggests features are intended to be numeric.
# If after pd.to_numeric, there are still object columns, you might need to drop them
X_for_mi = X.select_dtypes(include=np.number) # Select only numerical columns for mutual information

if not X_for_mi.empty:
    # Align columns for mutual_info_classif with point_biserial_coefs list
    # This requires careful indexing or ensuring both calculations are done on the same set of columns.
    # Let's re-calculate mutual_inf only for the columns we attempted point-biserial on
    mutual_inf = []
    for i in range(X.shape[1]):
        col_data = X.iloc[:, i]
        if pd.api.types.is_numeric_dtype(col_data) and col_data.nunique() > 1:
             # mutual_info_classif expects a 2D array-like for X
             try:
                 mi_score = mutual_info_classif(col_data.values.reshape(-1, 1), y)
                 mutual_inf.append(mi_score[0])
             except ValueError as e:
                 print(f"Could not calculate mutual information for column {X.columns[i]} due to error: {e}")
                 mutual_inf.append(np.nan)
        else:
            mutual_inf.append(np.nan) # Append NaN for non-applicable columns

else:
    print("No numerical columns available for mutual information calculation.")
    mutual_inf = [np.nan] * X.shape[1]


# Create a DataFrame to store feature importance
# Only include columns for which both calculations were attempted (or use a combined list of valid columns)
# Let's align the results based on the original X.columns
feature_importance = pd.DataFrame({'Mutual Inf': mutual_inf, 'Point-BiSerial': point_biserial_coefs}, index=X.columns)

# Create a DataFrame to store feature importance
feature_importance = pd.DataFrame({'Mutual Inf': mutual_inf, 'Point-BiSerial': point_biserial_coefs}, index=X.columns)

# Sort feature importance based on 'Point-BiSerial' column in descending order
sorted_feature_importance = feature_importance.sort_values(by='Point-BiSerial', ascending=False)

print(sorted_feature_importance)

feature_importance.sort_values(by = 'Mutual Inf', ascending = False)

print(X.columns)

SEED = 30
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, shuffle = True, random_state = SEED)

print('train samples ->', X_train.shape)
print('test samples ->', X_test.shape)

# Scaling numerical data
MM = MinMaxScaler()
MM_fit = MM.fit(X_train)
X_train = MM_fit.transform(X_train)
X_test = MM_fit.transform(X_test)

# Initialize the your model

from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier  # Import KNeighborsClassifier

model = KNeighborsClassifier(n_neighbors=5)  # You can adjust n_neighbors
#model =---------------------

# Train the model on the training data
model.fit(X_train, y_train)

# Make predictions
pred = model.predict(X_test)

# Convert y_test and pred to numerical values
y_test_numeric = y_test.map({'phishing': 0, 'legitimate': 1})
pred_numeric = pd.Series(pred).map({'phishing': 0, 'legitimate': 1}) # Convert pred numpy array to pandas Series for mapping

# Calculate Mean Squared Error and Accuracy Score
# Ensure both inputs to mean_squared_error are numerical
mse = mean_squared_error(y_test_numeric, pred_numeric) # Calculate MSE
acc = accuracy_score(y_test, pred) # Accuracy can use the original labels

print('Mean Squared Error : {0:.5f}'.format(mse))
print('Accuracy Score : {0:.2f} %'.format(acc * 100))

# classification report

clf_report = classification_report(pred, y_test, target_names = list(classes.values()))
print(clf_report)
# Generate confusion matrix and plot it
cm = confusion_matrix(y_test, pred)
# Changed 'display_statuss' to the correct argument 'display_labels'
cmd = ConfusionMatrixDisplay(cm, display_labels=list(classes.values()))

fig, ax = plt.subplots(figsize=(5, 5))
cmd.plot(ax=ax, cmap='BuPu', colorbar=False)

# Define GA hyperparameters
size = 100  # Population size
n_feat = X_train.shape[1]  # Number of features
n_parents = 50  # Number of parents to select
mutation_rate = 0.1  # Mutation rate
n_gen = 100  # Number of generations

# Function for initialization of population in GA
def initialization_of_population(size, n_feat):
    population = []
    for i in range(size):
        chromosome = np.ones(n_feat, dtype=bool)
        chromosome[:int(0.3 * n_feat)] = False
        np.random.shuffle(chromosome)
        population.append(chromosome)
    return population

def fitness_score(population):
    scores = []
    for chromosome in population:
        model.fit(X_train[:, chromosome], y_train)
        predictions = model.predict(X_test[:, chromosome])
        scores.append(accuracy_score(y_test, predictions))
    scores, population = np.array(scores), np.array(population)
    inds = np.argsort(scores)
    return list(scores[inds][::-1]), list(population[inds, :][::-1])

# Function for selection in GA
def selection(pop_after_fit, n_parents):
    population_nextgen = []
    for i in range(n_parents):
        population_nextgen.append(pop_after_fit[i])
    return population_nextgen

# Function for crossover in GA
def crossover(pop_after_sel):
    pop_nextgen = pop_after_sel
    for i in range(0, len(pop_after_sel), 2):
        new_par = []
        child_1, child_2 = pop_nextgen[i], pop_nextgen[i + 1]
        new_par = np.concatenate((child_1[:len(child_1) // 2], child_2[len(child_1) // 2:]))
        pop_nextgen.append(new_par)
    return pop_nextgen

# Function for mutation in GA
def mutation(pop_after_cross, mutation_rate, n_feat):
    mutation_range = int(mutation_rate * n_feat)
    pop_next_gen = []
    for n in range(0, len(pop_after_cross)):
        chromo = pop_after_cross[n]
        rand_posi = []
        for i in range(0, mutation_range):
            pos = np.random.randint(0, n_feat - 1)
            rand_posi.append(pos)
        for j in rand_posi:
            chromo[j] = not chromo[j]
        pop_next_gen.append(chromo)
    return pop_next_gen

# Function for GA generations
def generations(size, n_feat, n_parents, mutation_rate, n_gen, X_train, X_test, y_train, y_test):
    best_chromo = []
    best_score = []
    population_nextgen = initialization_of_population(size, n_feat)
    for i in range(n_gen):
        scores, pop_after_fit = fitness_score(population_nextgen)
        print('Best score in generation', i + 1, ':', scores[:1])  # Print best score in each generation
        pop_after_sel = selection(pop_after_fit, n_parents)
        pop_after_cross = crossover(pop_after_sel)
        population_nextgen = mutation(pop_after_cross, mutation_rate, n_feat)
        best_chromo.append(pop_after_fit[0])
        best_score.append(scores[0])
    return best_chromo, best_score

# Run GA after hyperparameter optimization
best_chromo, best_score = generations(size, n_feat, n_parents, mutation_rate, n_gen,
                                                               X_train, X_test, y_train, y_test)

# Get the best chromosome
best_chromosome = best_chromo[-1]

# Filter features based on the best chromosome
selected_features = X.columns[best_chromosome]

print("Best features selected by GA:")
print(selected_features)

# Select only the best features for training
X_train_ga = X_train[:, best_chromosome]
X_test_ga = X_test[:, best_chromosome]

# Initialize and train SVM model using the best features selected by GA
model_ga = KNeighborsClassifier(n_neighbors=5)  # You can adjust n_neighbors
model_ga.fit(X_train_ga, y_train)

# Make predictions
pred_ga = model_ga.predict(X_test_ga)

# Evaluate the model
acc_ga = accuracy_score(y_test, pred_ga)
print('Accuracy Score using selected features by GA: {0:.2f} %'.format(acc_ga * 100))

# Classification report
clf_report_ga = classification_report(y_test, pred_ga, target_names=list(classes.values()))
print("Classification Report using selected features by GA:")
print(clf_report_ga)

# Generate confusion matrix and plot it
cm_ga = confusion_matrix(y_test, pred_ga)
# Changed 'display_statuss' to the correct argument 'display_labels'
cmd_ga = ConfusionMatrixDisplay(cm_ga, display_labels=list(classes.values()))

fig, ax = plt.subplots(figsize=(5, 5))
cmd_ga.plot(ax=ax, cmap='BuPu', colorbar=False)
plt.title("Confusion Matrix using selected features by GA")
plt.show()

import numpy as np
from sklearn.metrics import accuracy_score

# PSO parameters
n_particles = 30       # Number of particles in the swarm
n_iterations = 50      # Number of iterations (generations)
n_features = X_train.shape[1]  # Number of features

w = 0.5                # Inertia weight
c1 = 1.5               # Cognitive component (personal best influence)
c2 = 1.5               # Social component (global best influence)

# Set random seed for reproducibility
np.random.seed(SEED)

# Initialize particles and velocities
particles = np.random.rand(n_particles, n_features)      # Positions (values between 0 and 1)
velocities = np.random.rand(n_particles, n_features)     # Velocities

# Initialize personal best positions and scores
personal_best_positions = particles.copy()
personal_best_scores = np.zeros(n_particles)

# Evaluate initial particles
for i in range(n_particles):
    selected = particles[i] > 0.5  # Binary mask for selected features
    if np.sum(selected) == 0:      # If no feature selected
        personal_best_scores[i] = 0
    else:

        model.fit(X_train[:, selected], y_train)
        preds = model.predict(X_test[:, selected])
        personal_best_scores[i] = accuracy_score(y_test, preds)

# Find the global best particle
global_best_idx = np.argmax(personal_best_scores)
global_best_position = personal_best_positions[global_best_idx].copy()

# PSO main loop
for iteration in range(n_iterations):
    for i in range(n_particles):
        # Generate random numbers for velocity update
        r1 = np.random.rand(n_features)
        r2 = np.random.rand(n_features)

        # Update velocity based on personal and global bests
        velocities[i] = (
            w * velocities[i]
            + c1 * r1 * (personal_best_positions[i] - particles[i])
            + c2 * r2 * (global_best_position - particles[i])
        )

        # Update particle position and clip to [0, 1]
        particles[i] += velocities[i]
        particles[i] = np.clip(particles[i], 0, 1)

        # Evaluate new position
        selected = particles[i] > 0.5
        if np.sum(selected) == 0:
            score = 0
        else:
            model = KNeighborsClassifier(n_neighbors=5)
            model.fit(X_train[:, selected], y_train)
            preds = model.predict(X_test[:, selected])
            score = accuracy_score(y_test, preds)

        # Update personal best if current score is better
        if score > personal_best_scores[i]:
            personal_best_scores[i] = score
            personal_best_positions[i] = particles[i].copy()

    # Update global best
    global_best_idx = np.argmax(personal_best_scores)
    global_best_position = personal_best_positions[global_best_idx].copy()

    print(f"Iteration {iteration+1}/{n_iterations}, Best Accuracy: {personal_best_scores[global_best_idx]:.4f}")

# Get the best feature subset from the final global best particle
best_features_mask = global_best_position > 0.5
selected_features = X.columns[best_features_mask]
print("Best features selected by PSO:")
print(selected_features)

# Train final model using selected features
X_train_pso = X_train[:, best_features_mask]
X_test_pso = X_test[:, best_features_mask]

final_model = KNeighborsClassifier(n_neighbors=5)
final_model.fit(X_train_pso, y_train)
pred_pso = final_model.predict(X_test_pso)
acc_pso = accuracy_score(y_test, pred_pso)

print("Accuracy using PSO-selected features: {:.2f}%".format(acc_pso * 100))

# Generate classification report
print("\nClassification Report after using PSO:")
print(classification_report(y_test, pred_pso))

# Generate confusion matrix
cm = confusion_matrix(y_test, pred_pso)
print("\nConfusion Matrix:")
print(cm)

# Plot confusion matrix (optional, requires matplotlib and seaborn)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Status") # Corrected from xstatus
plt.ylabel("True Status")     # Corrected from ystatus
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Define the metrics
metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy'] # Renamed from statuss

before = [0.92, 0.92, 0.92, 0.92]  # Macro avg + accuracy
ga     = [0.94, 0.94, 0.94, 0.94]
pso    = [0.93, 0.93, 0.93, 0.93]

# Bar width and x locations
x = np.arange(len(metrics))
width = 0.25

# Create plot
plt.figure(figsize=(10, 6))
# Changed 'status' to 'label'
plt.bar(x - width, before, width, label='Before FS', color='#1f77b4')
# Changed 'status' to 'label'
plt.bar(x, ga, width, label='After GA', color='#ff7f0e')
# Changed 'status' to 'label'
plt.bar(x + width, pso, width, label='After PSO', color='#2ca02c')

# labels and formatting
plt.ylabel('Score') # Changed from plt.ystatus
plt.ylim(0.90, 1.0)
plt.title('Model Performance Before and After Feature Selection')
plt.xticks(x, metrics) # Used the renamed variable
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()